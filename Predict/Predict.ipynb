{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.9.18 torch-2.2.0 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 7949MiB)\n",
      "Setup complete âœ… (20 CPUs, 15.4 GB RAM, 152.1/195.8 GB disk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Raw\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "%cd {HOME}/Images/Image_Raw/\n",
    "\n",
    "\n",
    "# Image(filename='predict.jpg', height = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Crop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Crop_Predicted\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}/Images/Image_Crop/\n",
    "%rm -rf *\n",
    "%cd {HOME}/Images/Image_Crop_Predicted/\n",
    "%rm -rf *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Crop Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {HOME}/Images/Image_Crop\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import Document\n",
    "from lxml import etree\n",
    "\n",
    "image_crop = []\n",
    "image_crop_topleft = []\n",
    "image_original = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crop_Image(imgname, dirsrc, dirdst, class_dict, subsize=800, gap=200, iou_thresh=0.3, ext='.png'):\n",
    "    \"\"\"\n",
    "    imgname:   å¾…è£åˆ‡å›¾åƒåï¼ˆå¸¦æ‰©å±•åï¼‰\n",
    "    dirsrc:    å¾…è£åˆ‡çš„å›¾åƒä¿å­˜ç›®å½•çš„ä¸Šä¸€ä¸ªç›®å½•ï¼Œé»˜è®¤å›¾åƒä¸Žæ ‡æ³¨æ–‡ä»¶åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹ï¼Œå›¾åƒåœ¨imagesä¸‹ï¼Œæ ‡æ³¨åœ¨labelTxtä¸‹ï¼Œæ ‡æ³¨æ–‡ä»¶æ ¼å¼ä¸ºæ¯è¡Œä¸€ä¸ªgt,\n",
    "               æ ¼å¼ä¸ºxmin,ymin,xmax,ymax,class,æƒ³è¯»å…¶ä»–æ ¼å¼è‡ªå·±åŠ¨æ‰‹æ”¹\n",
    "    dirdst:    è£åˆ‡çš„å›¾åƒä¿å­˜ç›®å½•çš„ä¸Šä¸€ä¸ªç›®å½•ï¼Œç›®å½•ä¸‹æœ‰images,labelTxtä¸¤ä¸ªç›®å½•åˆ†åˆ«ä¿å­˜è£åˆ‡å¥½çš„å›¾åƒæˆ–è€…txtæ–‡ä»¶ï¼Œ\n",
    "               ä¿å­˜çš„å›¾åƒå’Œtxtæ–‡ä»¶åæ ¼å¼ä¸º oriname_min_ymin.png(.txt),(xmin,ymin)ä¸ºè£åˆ‡å›¾åƒåœ¨åŽŸå›¾ä¸Šçš„å·¦ä¸Šç‚¹åæ ‡,txtæ ¼å¼å’ŒåŽŸæ–‡ä»¶æ ¼å¼ç›¸åŒ\n",
    "    subsize:   è£åˆ‡å›¾åƒçš„å°ºå¯¸ï¼Œé»˜è®¤ä¸ºæ­£æ–¹å½¢ï¼Œæƒ³è£åˆ‡çŸ©å½¢è‡ªå·±åŠ¨æ‰‹æ”¹\n",
    "    gap:       ç›¸é‚»è¡Œæˆ–åˆ—çš„å›¾åƒé‡å çš„å®½åº¦\n",
    "    iou_thresh:å°äºŽè¯¥é˜ˆå€¼çš„BBGTä¸ä¼šä¿å­˜åœ¨å¯¹åº”å›¾åƒçš„txtä¸­ï¼ˆåœ¨å›¾åƒè¿‡äºŽè¾¹ç¼˜æˆ–ä¸Žå›¾åƒæ— äº¤é›†ï¼‰\n",
    "    ext:       ä¿å­˜å›¾åƒçš„æ ¼å¼\n",
    "    \"\"\"\n",
    "    img = cv2.imread(os.path.join(os.path.join(dirsrc,'Image_Raw'), imgname), -1)\n",
    "    img_h,img_w = img.shape[:2]\n",
    "    \n",
    "    image_original.append(img)\n",
    "    print(img_h,img_w)\n",
    "    # Image(img, height = 600)\n",
    "    \n",
    "    top = 0\n",
    "    reachbottom = False\n",
    "    while not reachbottom:\n",
    "        reachright = False\n",
    "        left = 0\n",
    "        if top + subsize>=img_h:\n",
    "            reachbottom = True\n",
    "            top = max(img_h - subsize, 0)\n",
    "        while not reachright:\n",
    "            if left + subsize >= img_w:\n",
    "                reachright = True\n",
    "                left = max(img_w - subsize, 0)\n",
    "                \n",
    "            # imgsplit = img[top:min(top + subsize, img_h), left:min(left + subsize, img_w)].copy()\n",
    "            imgsplit = img[top:min(top + subsize, img_h), left:min(left + subsize, img_w)]\n",
    "            \n",
    "            if imgsplit.shape[:2] != (subsize,subsize):\n",
    "                template = np.zeros((subsize,subsize,3),dtype=np.uint8)\n",
    "                template[0:imgsplit.shape[0],0:imgsplit.shape[1]] = imgsplit\n",
    "                # imgsplit = template.copy()\n",
    "                imgsplit = template\n",
    "\n",
    "            cv2.imwrite(os.path.join(dirdst, imgname.split('.')[0] + '_' + str(left) + '_' + str(top) + ext), imgsplit)\n",
    "            image_crop.append(imgsplit)\n",
    "            image_crop_topleft.append((top, left))\n",
    "            left += subsize-gap\n",
    "        top+=subsize-gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drillbit8_t5878_tb21_v16.jpg\n",
      "3692 5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "dirsrc= f'{HOME}/Images'  #'/home/skyarrow/Workspace/Drillbit-Detection/Calculate_Numbers'      #å¾…è£å‰ªå›¾åƒæ‰€åœ¨ç›®å½•çš„ä¸Šçº§ç›®å½•ï¼Œå›¾åƒåœ¨JPEGImagesæ–‡ä»¶å¤¹ä¸‹ï¼Œæ ‡æ³¨æ–‡ä»¶åœ¨Annotationsä¸‹\n",
    "dirdst= f'{HOME}/Images/Image_Crop'   #è£å‰ªç»“æžœå­˜æ”¾ç›®å½•ï¼Œæ ¼å¼å’ŒåŽŸå›¾åƒç›®å½•ä¸€æ ·\n",
    "\n",
    "if not os.path.exists(dirdst):\n",
    "    os.mkdir(dirdst)\n",
    "if not os.path.exists(dirdst):\n",
    "    os.mkdir(dirdst)\n",
    "\n",
    "\n",
    "class_dict = {'0': 0,'1': 1, '2': 2, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, '10':10}\n",
    "name_dict = {'0': 'tool', '1': 'tool_b', '2': 'void'}\n",
    "subsize = 640  #è£åˆ‡å›¾åƒçš„å°ºå¯¸ åŽŸæ¥æ˜¯512\n",
    "gap = 300 #ç›¸é‚»è¡Œæˆ–åˆ—çš„å›¾åƒé‡å çš„å®½åº¦\n",
    "iou_thresh = 0.4\n",
    "ext = '.jpg'\n",
    "num_thresh = 8\n",
    "\n",
    "imglist = glob.glob(f'{dirsrc}/Image_Raw/*.jpg')\n",
    "imgnameList = [os.path.split(imgpath)[-1] for imgpath in imglist]\n",
    "for imgname in tqdm.tqdm(imgnameList):\n",
    "    print(imgname)\n",
    "    Crop_Image(imgname, dirsrc, dirdst, class_dict, subsize, gap, iou_thresh, ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predict & Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_IOU(box1, box2):\n",
    "    \"\"\"\n",
    "    box1: (xmin, ymin, xmax, ymax)\n",
    "    box2: (xmin, ymin, xmax, ymax)\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    overlap = x_overlap * y_overlap\n",
    "    iou = overlap / (area1 + area2 - overlap)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of crops: 160\n",
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Crop_Predicted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 (no detections), 32.6ms\n",
      "Speed: 2.8ms preprocess, 32.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.4ms\n",
      "Speed: 2.1ms preprocess, 29.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 tools, 34.0ms\n",
      "Speed: 1.7ms preprocess, 34.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 36 tools, 32.6ms\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 49 tools, 32.6ms\n",
      "Speed: 1.7ms preprocess, 32.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 53 tools, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 72 tools, 32.7ms\n",
      "Speed: 1.7ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 72 tools, 31.9ms\n",
      "Speed: 2.0ms preprocess, 31.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 92 tools, 34.7ms\n",
      "Speed: 1.7ms preprocess, 34.7ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 96 tools, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 99 tools, 1 void, 28.0ms\n",
      "Speed: 2.1ms preprocess, 28.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 113 tools, 1 tool_b, 1 void, 28.6ms\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 67 tools, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 6 tools, 28.2ms\n",
      "Speed: 2.4ms preprocess, 28.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 31.9ms\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 34.4ms\n",
      "Speed: 1.8ms preprocess, 34.4ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 tools, 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 130 tools, 33.0ms\n",
      "Speed: 2.2ms preprocess, 33.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 180 tools, 27.1ms\n",
      "Speed: 1.9ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 193 tools, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 195 tools, 1 tool_b, 24.6ms\n",
      "Speed: 3.0ms preprocess, 24.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 197 tools, 1 tool_b, 30.4ms\n",
      "Speed: 1.7ms preprocess, 30.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 193 tools, 1 void, 27.7ms\n",
      "Speed: 2.3ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 183 tools, 2 tool_bs, 1 void, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 183 tools, 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 181 tools, 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 46 tools, 26.9ms\n",
      "Speed: 2.5ms preprocess, 26.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.5ms\n",
      "Speed: 2.8ms preprocess, 28.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.0ms\n",
      "Speed: 2.5ms preprocess, 25.0ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 31 tools, 2 voids, 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 171 tools, 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 183 tools, 2 tool_bs, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 191 tools, 2 tool_bs, 1 void, 30.5ms\n",
      "Speed: 1.6ms preprocess, 30.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 191 tools, 1 tool_b, 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 188 tools, 1 void, 29.4ms\n",
      "Speed: 1.5ms preprocess, 29.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 185 tools, 2 tool_bs, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 186 tools, 1 tool_b, 2 voids, 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 118 tools, 1 void, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 tools, 2 tool_bs, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.0ms\n",
      "Speed: 3.2ms preprocess, 29.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.0ms\n",
      "Speed: 1.9ms preprocess, 27.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 85 tools, 2 voids, 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 178 tools, 31.6ms\n",
      "Speed: 1.6ms preprocess, 31.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 188 tools, 30.2ms\n",
      "Speed: 1.6ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 191 tools, 2 tool_bs, 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 186 tools, 23.6ms\n",
      "Speed: 3.2ms preprocess, 23.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 191 tools, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 177 tools, 1 tool_b, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 41 tools, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 1 tool_b, 31.3ms\n",
      "Speed: 1.6ms preprocess, 31.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.4ms\n",
      "Speed: 1.7ms preprocess, 26.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 31.9ms\n",
      "Speed: 2.2ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 28.2ms\n",
      "Speed: 1.7ms preprocess, 28.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 16 tools, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 145 tools, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 185 tools, 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 183 tools, 1 tool_b, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 181 tools, 2 tool_bs, 3 voids, 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 180 tools, 3 tool_bs, 29.5ms\n",
      "Speed: 1.6ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 112 tools, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 tools, 30.5ms\n",
      "Speed: 1.6ms preprocess, 30.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.7ms\n",
      "Speed: 2.1ms preprocess, 27.7ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.6ms\n",
      "Speed: 1.4ms preprocess, 30.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 55 tools, 32.4ms\n",
      "Speed: 1.7ms preprocess, 32.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 162 tools, 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 188 tools, 1 tool_b, 26.6ms\n",
      "Speed: 2.2ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 182 tools, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 174 tools, 1 tool_b, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 44 tools, 26.1ms\n",
      "Speed: 2.2ms preprocess, 26.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 tools, 29.1ms\n",
      "Speed: 1.7ms preprocess, 29.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.2ms\n",
      "Speed: 2.0ms preprocess, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 31.9ms\n",
      "Speed: 1.5ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 tools, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 111 tools, 1 void, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 170 tools, 1 void, 30.9ms\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 177 tools, 2 voids, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 113 tools, 23.2ms\n",
      "Speed: 1.7ms preprocess, 23.2ms inference, 5.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 tools, 26.5ms\n",
      "Speed: 2.5ms preprocess, 26.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 32.5ms\n",
      "Speed: 1.7ms preprocess, 32.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.2ms\n",
      "Speed: 2.6ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.1ms\n",
      "Speed: 1.5ms preprocess, 30.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 23 tools, 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 144 tools, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 165 tools, 2 voids, 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 43 tools, 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 31.1ms\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 32.1ms\n",
      "Speed: 1.5ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 30.2ms\n",
      "Speed: 1.5ms preprocess, 30.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 tools, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 71 tools, 27.0ms\n",
      "Speed: 1.7ms preprocess, 27.0ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 89 tools, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 tools, 23.5ms\n",
      "Speed: 3.7ms preprocess, 23.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 25.4ms\n",
      "Speed: 2.5ms preprocess, 25.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 32.6ms\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.2ms\n",
      "Speed: 2.4ms preprocess, 26.2ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.2ms\n",
      "Speed: 1.5ms preprocess, 29.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.0ms\n",
      "Speed: 2.2ms preprocess, 25.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.3ms\n",
      "Speed: 1.5ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 tools, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 20 tools, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 tools, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 29.3ms\n",
      "Speed: 2.7ms preprocess, 29.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 21.4ms\n",
      "Speed: 1.8ms preprocess, 21.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 25.7ms\n",
      "Speed: 1.7ms preprocess, 25.7ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 32.1ms\n",
      "Speed: 1.5ms preprocess, 32.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number = 5907\n",
      "Boxes Number = 5907\n",
      "Average Area = 913.3157271034366\n",
      "Class tool = 5900\n",
      "Class tool_b = 0\n",
      "Class void = 7\n",
      "Answer: tool:5878 tool_b:21 void:16\n",
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Results\n",
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of crops: {len(image_crop)}')\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Weights/train4_augdata_batch4_epoch100.pt')  # load the best checkpoint\n",
    "model.max_boxes = 500\n",
    "model.max_detection_points = 500\n",
    "predst = f'{HOME}/Images/Image_Crop_Predicted/'\n",
    "%cd {HOME}/Images/Image_Crop_Predicted/\n",
    "\n",
    "\n",
    "image_big = image_original[0]\n",
    "image_draw = image_original[0].copy()\n",
    "bboxes = []\n",
    "idx = 0\n",
    "touch_edge = 10\n",
    "touch_edge1 = 30\n",
    "hw_ratio = 1.4\n",
    "IOU_ratio = 0.2\n",
    "total_area = 0\n",
    "cover_pixel = 3\n",
    "color = {'0': (162, 84, 66), '1': (25, 90, 192), '2': (168, 73, 138), '3': (255, 255, 0), '4': (0, 255, 255)}\n",
    "cls_count = {'0': 0, '1': 0, '2': 0}\n",
    "total_count = 0\n",
    "avg_area = 0\n",
    "\n",
    "def Touch_Edge(box):\n",
    "    if (abs(int(box[0]) - 0) <= touch_edge) or (abs(int(box[1]) - 0) <= touch_edge) or (abs(int(box[2]) - 640) <= touch_edge) or (abs(int(box[3]) - 640) <= touch_edge):\n",
    "        # print(f\"Touch edge: {box}\" )\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def Shape_Unlikely(box):\n",
    "    global total_area, total_count, avg_area\n",
    "    h = box[3] - box[1]\n",
    "    w = box[2] - box[0]\n",
    "    area = h * w\n",
    "    if (h/w > hw_ratio) or (w/h > hw_ratio):\n",
    "        # print(f\"Shape unlikely: {box}\")\n",
    "        return True\n",
    "    else:\n",
    "        if total_count > 50:\n",
    "            avg_area = total_area / total_count\n",
    "            if (area > avg_area * 1.4) or (area < avg_area * 0.6):\n",
    "                return True\n",
    "        else:\n",
    "            return False  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for img in image_crop:\n",
    "    # now_img = img.copy()\n",
    "    now_img = img\n",
    "    results = model(now_img)  # return a list of Results objects\n",
    "\n",
    "    # Process results list\n",
    "    for result in results:\n",
    "        # print(len(results))\n",
    "        boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "        classes = boxes.cls\n",
    "        \n",
    "        now_idx = 0\n",
    "        for box in boxes.xyxy:\n",
    "            x1 = int(box[0]) + image_crop_topleft[idx][1]\n",
    "            y1 = int(box[1]) + image_crop_topleft[idx][0]\n",
    "            x2 = int(box[2]) + image_crop_topleft[idx][1]\n",
    "            y2 = int(box[3]) + image_crop_topleft[idx][0]\n",
    "            now_box = (x1, y1, x2, y2)\n",
    "            now_cls = boxes.cls[now_idx]\n",
    "            now_cls = int(now_cls)\n",
    "            \n",
    "            \n",
    "            # if now_cls == 1:\n",
    "            #     print('111')\n",
    "            #     cv2.rectangle(image_draw, (x1, y1), (x2, y2), color[str(now_cls)], 3)\n",
    "            \n",
    "            if(Touch_Edge(box) or Shape_Unlikely(box)):\n",
    "                continue\n",
    "            \n",
    "            overlap = False\n",
    "            for bbox in bboxes:\n",
    "                if Calculate_IOU(bbox, now_box) > IOU_ratio:\n",
    "                    overlap = True\n",
    "                    # print(f\"Overlap: {bbox} and {now_box}\")\n",
    "                    break\n",
    "                \n",
    "            \n",
    "            edge_cnt = 0\n",
    "            if not overlap:\n",
    "                bboxes.append(now_box)\n",
    "                total_area += (x2 - x1) * (y2 - y1)\n",
    "                \n",
    "                \n",
    "                # print(f'Class: {now_cls}')\n",
    "                cls_count[str(now_cls)] += 1\n",
    "                total_count += 1\n",
    "                \n",
    "                cv2.rectangle(image_draw, (x1, y1), (x2, y2), color[str(now_cls)], 3)\n",
    "                # now_img = cv2.rectangle(now_img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "                image_big[y1+cover_pixel:y2-cover_pixel, x1+cover_pixel:x2-cover_pixel, :] = (0, 0, 0)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            now_idx += 1\n",
    "    cv2.imwrite(os.path.join(predst, f'image{idx}_predicted.jpg'), now_img)\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total Number = {total_count}\")\n",
    "print(f\"Boxes Number = {len(bboxes)}\")\n",
    "print(f\"Average Area = {total_area / total_count}\")\n",
    "for cls, num in cls_count.items():\n",
    "    print(f'Class {name_dict[str(cls)]} = {num}')\n",
    "\n",
    "# print(f'Answer: tool:1 tool_b:498 void:1')\n",
    "# answer_num = 500\n",
    "print(f'Answer: tool:5929 tool_b:11 void:13')\n",
    "answer_num = 5953\n",
    "# print(f'Answer: tool:5878 tool_b:21 void:16')\n",
    "# answer_num = 5915\n",
    "\n",
    "\n",
    "%cd {HOME}/Images/Image_Results/\n",
    "cv2.putText(image_draw, f\"Total Number = {total_count}\", (150, 150), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image_draw, f\"Tool Number = {cls_count['0']}\", (150, 250), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image_draw, f\"Tool_b Number = {cls_count['1']}\", (150, 350), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image_draw, f\"Void Number = {cls_count['2']}\", (150, 450), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image_draw, f'Answer: tool:5921 tool_b:11 void:13', (150, 550), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image_draw, 'Number Precision : {:.3%}'.format(1.0 - (abs(total_count - answer_num)/answer_num)), (150, 650), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.imwrite('result.jpg', image_draw)\n",
    "cv2.imwrite('filtered.jpg', image_big)\n",
    "\n",
    "%cd {HOME}\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
