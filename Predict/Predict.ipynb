{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.196 🚀 Python-3.9.18 torch-2.2.0 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 7949MiB)\n",
      "Setup complete ✅ (20 CPUs, 15.4 GB RAM, 147.1/195.8 GB disk)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Raw\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "%cd {HOME}/Images/Image_Raw/\n",
    "\n",
    "\n",
    "# Image(filename='predict.jpg', height = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Crop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Crop_Predicted\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}/Images/Image_Crop/\n",
    "%rm -rf *\n",
    "%cd {HOME}/Images/Image_Crop_Predicted/\n",
    "%rm -rf *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Crop Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {HOME}/Images/Image_Crop\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom.minidom import Document\n",
    "from lxml import etree\n",
    "\n",
    "image_crop = []\n",
    "image_crop_topleft = []\n",
    "image_original = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crop_Image(imgname, dirsrc, dirdst, class_dict, subsize=800, gap=200, iou_thresh=0.3, ext='.png'):\n",
    "    \"\"\"\n",
    "    imgname:   待裁切图像名（带扩展名）\n",
    "    dirsrc:    待裁切的图像保存目录的上一个目录，默认图像与标注文件在一个文件夹下，图像在images下，标注在labelTxt下，标注文件格式为每行一个gt,\n",
    "               格式为xmin,ymin,xmax,ymax,class,想读其他格式自己动手改\n",
    "    dirdst:    裁切的图像保存目录的上一个目录，目录下有images,labelTxt两个目录分别保存裁切好的图像或者txt文件，\n",
    "               保存的图像和txt文件名格式为 oriname_min_ymin.png(.txt),(xmin,ymin)为裁切图像在原图上的左上点坐标,txt格式和原文件格式相同\n",
    "    subsize:   裁切图像的尺寸，默认为正方形，想裁切矩形自己动手改\n",
    "    gap:       相邻行或列的图像重叠的宽度\n",
    "    iou_thresh:小于该阈值的BBGT不会保存在对应图像的txt中（在图像过于边缘或与图像无交集）\n",
    "    ext:       保存图像的格式\n",
    "    \"\"\"\n",
    "    img = cv2.imread(os.path.join(os.path.join(dirsrc,'Image_Raw'), imgname), -1)\n",
    "    img_h,img_w = img.shape[:2]\n",
    "    \n",
    "    image_original.append(img)\n",
    "    print(img_h,img_w)\n",
    "    # Image(img, height = 600)\n",
    "    \n",
    "    top = 0\n",
    "    reachbottom = False\n",
    "    while not reachbottom:\n",
    "        reachright = False\n",
    "        left = 0\n",
    "        if top + subsize>=img_h:\n",
    "            reachbottom = True\n",
    "            top = max(img_h - subsize, 0)\n",
    "        while not reachright:\n",
    "            if left + subsize >= img_w:\n",
    "                reachright = True\n",
    "                left = max(img_w - subsize, 0)\n",
    "                \n",
    "            # imgsplit = img[top:min(top + subsize, img_h), left:min(left + subsize, img_w)].copy()\n",
    "            imgsplit = img[top:min(top + subsize, img_h), left:min(left + subsize, img_w)]\n",
    "            \n",
    "            if imgsplit.shape[:2] != (subsize,subsize):\n",
    "                template = np.zeros((subsize,subsize,3),dtype=np.uint8)\n",
    "                template[0:imgsplit.shape[0],0:imgsplit.shape[1]] = imgsplit\n",
    "                # imgsplit = template.copy()\n",
    "                imgsplit = template\n",
    "\n",
    "            cv2.imwrite(os.path.join(dirdst, imgname.split('.')[0] + '_' + str(left) + '_' + str(top) + ext), imgsplit)\n",
    "            image_crop.append(imgsplit)\n",
    "            image_crop_topleft.append((top, left))\n",
    "            left += subsize-gap\n",
    "        top+=subsize-gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_3_n.jpg\n",
      "3692 5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "dirsrc= f'{HOME}/Images'  #'/home/skyarrow/Workspace/Drillbit-Detection/Calculate_Numbers'      #待裁剪图像所在目录的上级目录，图像在JPEGImages文件夹下，标注文件在Annotations下\n",
    "dirdst= f'{HOME}/Images/Image_Crop'   #裁剪结果存放目录，格式和原图像目录一样\n",
    "\n",
    "if not os.path.exists(dirdst):\n",
    "    os.mkdir(dirdst)\n",
    "if not os.path.exists(dirdst):\n",
    "    os.mkdir(dirdst)\n",
    "\n",
    "\n",
    "class_dict = {'0': 0,'1': 1, '2': 2, '3':3, '4':4, '5':5, '6':6, '7':7, '8':8, '9':9, '10':10}\n",
    "name_dict = {'0': 'tool', '1': 'tool_b', '2': 'void'}\n",
    "subsize = 640  #裁切图像的尺寸 原来是512\n",
    "gap = 300 #相邻行或列的图像重叠的宽度\n",
    "iou_thresh = 0.4\n",
    "ext = '.jpg'\n",
    "num_thresh = 8\n",
    "\n",
    "imglist = glob.glob(f'{dirsrc}/Image_Raw/*.jpg')\n",
    "imgnameList = [os.path.split(imgpath)[-1] for imgpath in imglist]\n",
    "for imgname in tqdm.tqdm(imgnameList):\n",
    "    print(imgname)\n",
    "    Crop_Image(imgname, dirsrc, dirdst, class_dict, subsize, gap, iou_thresh, ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predict & Assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_IOU(box1, box2):\n",
    "    \"\"\"\n",
    "    box1: (xmin, ymin, xmax, ymax)\n",
    "    box2: (xmin, ymin, xmax, ymax)\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "    x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "    y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "    area1 = (x2 - x1) * (y2 - y1)\n",
    "    area2 = (x4 - x3) * (y4 - y3)\n",
    "    overlap = x_overlap * y_overlap\n",
    "    iou = overlap / (area1 + area2 - overlap)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 6.3ms\n",
      "Speed: 1.2ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 33 tools, 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of crops: 160\n",
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Crop_Predicted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x640 60 tools, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 65 tools, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 60 tools, 2 tool_bs, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 62 tools, 1 tool_b, 6.4ms\n",
      "Speed: 1.1ms preprocess, 6.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 60 tools, 2 tool_bs, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 63 tools, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 60 tools, 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 66 tools, 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 63 tools, 1 tool_b, 7.3ms\n",
      "Speed: 1.0ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 43 tools, 1 tool_b, 6.8ms\n",
      "Speed: 0.9ms preprocess, 6.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 tools, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.2ms\n",
      "Speed: 0.9ms preprocess, 7.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 5 tools, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 36 tools, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 54 tools, 6.4ms\n",
      "Speed: 1.1ms preprocess, 6.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 50 tools, 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 50 tools, 6.1ms\n",
      "Speed: 1.1ms preprocess, 6.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 46 tools, 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 57 tools, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 52 tools, 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 51 tools, 5.8ms\n",
      "Speed: 1.1ms preprocess, 5.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 43 tools, 1 tool_b, 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 12 tools, 6.7ms\n",
      "Speed: 1.1ms preprocess, 6.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.8ms\n",
      "Speed: 1.3ms preprocess, 5.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.4ms\n",
      "Speed: 1.1ms preprocess, 6.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.8ms\n",
      "Speed: 1.1ms preprocess, 6.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 19 tools, 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 48 tools, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 56 tools, 6.5ms\n",
      "Speed: 1.1ms preprocess, 6.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 55 tools, 6.5ms\n",
      "Speed: 1.1ms preprocess, 6.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 59 tools, 6.4ms\n",
      "Speed: 1.1ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 60 tools, 5.3ms\n",
      "Speed: 1.2ms preprocess, 5.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 50 tools, 1 tool_b, 5.2ms\n",
      "Speed: 1.1ms preprocess, 5.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 55 tools, 1 tool_b, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 29 tools, 1 tool_b, 5.3ms\n",
      "Speed: 1.1ms preprocess, 5.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 tools, 6.7ms\n",
      "Speed: 1.2ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.8ms\n",
      "Speed: 0.9ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.2ms\n",
      "Speed: 1.1ms preprocess, 5.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.6ms\n",
      "Speed: 1.1ms preprocess, 5.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 tools, 2 tool_bs, 6.2ms\n",
      "Speed: 1.7ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 36 tools, 3 tool_bs, 5.6ms\n",
      "Speed: 0.9ms preprocess, 5.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 46 tools, 3 tool_bs, 5.6ms\n",
      "Speed: 1.1ms preprocess, 5.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 52 tools, 3 tool_bs, 6.4ms\n",
      "Speed: 1.1ms preprocess, 6.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 52 tools, 1 tool_b, 5.2ms\n",
      "Speed: 1.1ms preprocess, 5.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 52 tools, 2 tool_bs, 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 60 tools, 5.6ms\n",
      "Speed: 1.2ms preprocess, 5.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 48 tools, 3 tool_bs, 5.7ms\n",
      "Speed: 1.1ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 tools, 4 tool_bs, 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.8ms\n",
      "Speed: 1.2ms preprocess, 5.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.8ms\n",
      "Speed: 1.1ms preprocess, 5.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.6ms\n",
      "Speed: 1.1ms preprocess, 5.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.2ms\n",
      "Speed: 1.1ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.0ms\n",
      "Speed: 0.9ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 15 tools, 1 tool_b, 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 45 tools, 5.3ms\n",
      "Speed: 1.0ms preprocess, 5.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 56 tools, 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 53 tools, 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 51 tools, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 54 tools, 5.4ms\n",
      "Speed: 1.1ms preprocess, 5.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 24 tools, 1 tool_b, 6.2ms\n",
      "Speed: 1.1ms preprocess, 6.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.1ms\n",
      "Speed: 0.9ms preprocess, 6.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 1 tool_b, 5.4ms\n",
      "Speed: 1.1ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.4ms\n",
      "Speed: 1.1ms preprocess, 5.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 1.2ms preprocess, 5.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 tools, 1 tool_b, 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 28 tools, 4 tool_bs, 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 48 tools, 4 tool_bs, 5.9ms\n",
      "Speed: 1.2ms preprocess, 5.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 43 tools, 2 tool_bs, 6.2ms\n",
      "Speed: 1.1ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 43 tools, 3 tool_bs, 6.2ms\n",
      "Speed: 1.2ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 32 tools, 2 tool_bs, 5.4ms\n",
      "Speed: 1.1ms preprocess, 5.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 tools, 1 tool_b, 5.3ms\n",
      "Speed: 1.0ms preprocess, 5.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool_b, 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.0ms\n",
      "Speed: 1.1ms preprocess, 6.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.6ms\n",
      "Speed: 1.2ms preprocess, 5.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.6ms\n",
      "Speed: 1.5ms preprocess, 5.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.4ms\n",
      "Speed: 1.4ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.6ms\n",
      "Speed: 1.4ms preprocess, 5.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 tools, 6.0ms\n",
      "Speed: 0.9ms preprocess, 6.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 43 tools, 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 52 tools, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 52 tools, 5.4ms\n",
      "Speed: 1.1ms preprocess, 5.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 22 tools, 5.4ms\n",
      "Speed: 1.2ms preprocess, 5.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.5ms\n",
      "Speed: 1.2ms preprocess, 5.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.4ms\n",
      "Speed: 1.0ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.8ms\n",
      "Speed: 1.0ms preprocess, 5.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 0.9ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool, 6.5ms\n",
      "Speed: 0.9ms preprocess, 6.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 29 tools, 1 tool_b, 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 52 tools, 6.6ms\n",
      "Speed: 1.1ms preprocess, 6.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 41 tools, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 tools, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.2ms\n",
      "Speed: 0.9ms preprocess, 6.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.6ms\n",
      "Speed: 0.8ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.3ms\n",
      "Speed: 1.1ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 0.8ms preprocess, 5.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 1.1ms preprocess, 5.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 tools, 1 tool_b, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 34 tools, 5 tool_bs, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 14 tools, 2 tool_bs, 5.0ms\n",
      "Speed: 1.2ms preprocess, 5.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tool_b, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.2ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 1.5ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.5ms\n",
      "Speed: 1.2ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.8ms\n",
      "Speed: 0.9ms preprocess, 6.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.6ms\n",
      "Speed: 0.9ms preprocess, 5.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 0.9ms preprocess, 5.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 tools, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 tools, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.4ms\n",
      "Speed: 1.0ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.4ms\n",
      "Speed: 0.9ms preprocess, 7.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.0ms\n",
      "Speed: 0.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 6.7ms\n",
      "Speed: 0.9ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.7ms\n",
      "Speed: 0.9ms preprocess, 5.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number = 1425\n",
      "Boxes Number = 1425\n",
      "Average Area = 4667.825263157894\n",
      "Class tool = 1425\n",
      "Class tool_b = 0\n",
      "Class void = 0\n",
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Images/Image_Results\n",
      "/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of crops: {len(image_crop)}')\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('/home/skyarrow/Workspace/Yolov8-Drillbit-Detection/Predict/Weights/train2_fulldata_batch4_epoch200.pt')  # load the best checkpoint\n",
    "model.max_boxes = 500\n",
    "model.max_detection_points = 500\n",
    "predst = f'{HOME}/Images/Image_Crop_Predicted/'\n",
    "%cd {HOME}/Images/Image_Crop_Predicted/\n",
    "\n",
    "\n",
    "image_big = image_original[0]\n",
    "image_draw = image_original[0].copy()\n",
    "bboxes = []\n",
    "idx = 0\n",
    "touch_edge = 10\n",
    "touch_edge1 = 30\n",
    "hw_ratio = 1.4\n",
    "IOU_ratio = 0.2\n",
    "total_area = 0\n",
    "cover_pixel = 3\n",
    "color = {'0': (162, 84, 66), '1': (25, 90, 192), '2': (168, 73, 138), '3': (255, 255, 0), '4': (0, 255, 255)}\n",
    "cls_count = {'0': 0, '1': 0, '2': 0}\n",
    "total_count = 0\n",
    "avg_area = 0\n",
    "\n",
    "def Touch_Edge(box):\n",
    "    if (abs(int(box[0]) - 0) <= touch_edge) or (abs(int(box[1]) - 0) <= touch_edge) or (abs(int(box[2]) - 640) <= touch_edge) or (abs(int(box[3]) - 640) <= touch_edge):\n",
    "        # print(f\"Touch edge: {box}\" )\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def Shape_Unlikely(box):\n",
    "    global total_area, total_count, avg_area\n",
    "    h = box[3] - box[1]\n",
    "    w = box[2] - box[0]\n",
    "    area = h * w\n",
    "    if (h/w > hw_ratio) or (w/h > hw_ratio):\n",
    "        # print(f\"Shape unlikely: {box}\")\n",
    "        return True\n",
    "    else:\n",
    "        if total_count > 50:\n",
    "            avg_area = total_area / total_count\n",
    "            if area > avg_area * 1.4:\n",
    "                return True\n",
    "        else:\n",
    "            return False  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for img in image_crop:\n",
    "    # now_img = img.copy()\n",
    "    now_img = img\n",
    "    results = model(now_img)  # return a list of Results objects\n",
    "\n",
    "    # Process results list\n",
    "    for result in results:\n",
    "        # print(len(results))\n",
    "        boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "        classes = boxes.cls\n",
    "        \n",
    "        now_idx = 0\n",
    "        for box in boxes.xyxy:\n",
    "            x1 = int(box[0]) + image_crop_topleft[idx][1]\n",
    "            y1 = int(box[1]) + image_crop_topleft[idx][0]\n",
    "            x2 = int(box[2]) + image_crop_topleft[idx][1]\n",
    "            y2 = int(box[3]) + image_crop_topleft[idx][0]\n",
    "            now_box = (x1, y1, x2, y2)\n",
    "            now_cls = boxes.cls[now_idx]\n",
    "            now_cls = int(now_cls)\n",
    "            \n",
    "            \n",
    "            # if now_cls == 1:\n",
    "            #     print('111')\n",
    "            #     cv2.rectangle(image_draw, (x1, y1), (x2, y2), color[str(now_cls)], 3)\n",
    "            \n",
    "            if(Touch_Edge(box) or Shape_Unlikely(box)):\n",
    "                continue\n",
    "            \n",
    "            overlap = False\n",
    "            for bbox in bboxes:\n",
    "                if Calculate_IOU(bbox, now_box) > IOU_ratio:\n",
    "                    overlap = True\n",
    "                    # print(f\"Overlap: {bbox} and {now_box}\")\n",
    "                    break\n",
    "                \n",
    "            \n",
    "            edge_cnt = 0\n",
    "            if not overlap:\n",
    "                bboxes.append(now_box)\n",
    "                total_area += (x2 - x1) * (y2 - y1)\n",
    "                \n",
    "                \n",
    "                # print(f'Class: {now_cls}')\n",
    "                cls_count[str(now_cls)] += 1\n",
    "                total_count += 1\n",
    "                \n",
    "                cv2.rectangle(image_draw, (x1, y1), (x2, y2), color[str(now_cls)], 3)\n",
    "                # now_img = cv2.rectangle(now_img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "                image_big[y1+cover_pixel:y2-cover_pixel, x1+cover_pixel:x2-cover_pixel, :] = (0, 0, 0)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            now_idx += 1\n",
    "    cv2.imwrite(os.path.join(predst, f'image{idx}_predicted.jpg'), now_img)\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total Number = {total_count}\")\n",
    "print(f\"Boxes Number = {len(bboxes)}\")\n",
    "print(f\"Average Area = {total_area / total_count}\")\n",
    "for cls, num in cls_count.items():\n",
    "    print(f'Class {name_dict[str(cls)]} = {num}')\n",
    "\n",
    "# print(f'Answer: tool:1 tool_b:498 void:1')\n",
    "# answer_num = 500\n",
    "# print(f'Answer: tool:5929 tool_b:11 void:13')\n",
    "# answer_num = 5953\n",
    "# print(f'Answer: tool:5878 tool_b:21 void:16')\n",
    "# answer_num = 5915\n",
    "\n",
    "\n",
    "%cd {HOME}/Images/Image_Results/\n",
    "cv2.putText(image_draw, f\"Total Number = {total_count}\", (150, 150), cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image_draw, f\"Tool Number = {cls_count['0']}\", (150, 250), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image_draw, f\"Tool_b Number = {cls_count['1']}\", (150, 350), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.putText(image_draw, f\"Void Number = {cls_count['2']}\", (150, 450), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "# cv2.putText(image_draw, f'Answer: tool:1 tool_b:498 void:1', (150, 550), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "# cv2.putText(image_draw, 'Number Precision : {:.3%}'.format(1.0 - (abs(total_count - answer_num)/answer_num)), (150, 650), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "cv2.imwrite('result.jpg', image_draw)\n",
    "cv2.imwrite('filtered.jpg', image_big)\n",
    "\n",
    "%cd {HOME}\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
